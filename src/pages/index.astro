---
import Layout from '../layouts/Layout.astro'
import { Image } from 'astro:assets'

import { profile } from '@/settings'
import { experiences, education } from '@/data/cv'
import ProfilePictures from '@/assets/profile_pictures.jpg'
import AdobeFireflyLogo from '@/assets/brands/Adobe_Firefly_Logo.png'
import RephraseLogo from '@/assets/brands/rephrase.png'
import ZomatoLogo from '@/assets/brands/Zomato_Logo.svg'
import SamsungLogo from '@/assets/brands/samsung.svg'
import IitkgpLogo from '@/assets/brands/iitkgp.svg'
import FireflyDemoVideo from '@/assets/projects/translate_video.mp4'
import TextToAvatarAsset from '@/assets/projects/text_to_avatar.webp'
import ImageEnhancementAsset from '@/assets/projects/image_enhancement.avif'
import FacenetSiameseAsset from '@/assets/projects/facenet_siamese.png'
import ClipImageTaggingAsset from '@/assets/projects/clip_image_tagging.png'
import GestureRecognitionAsset from '@/assets/projects/gesture_recognition.png'
import HumanActionClassificationAsset from '@/assets/projects/human_action_classification.png'
import CsiNetAsset from '@/assets/projects/csinet.png'
import LensfreeAsset from '@/assets/projects/lesnfree.gif'
import Hero from '@/components/ui/Hero.astro'
import CvTimeline from '@/components/ui/CvTimeline.astro'
import type { Experience, Education } from '@/types/cv'

const { fullName, title, institute } = profile
const fireflyWebsite = 'https://www.adobe.com/products/firefly/features/translate-video.html'
const avatarWebsite = 'https://www.adobe.com/in/products/firefly/features/ai-avatar-generator.html'
const zomatoWebsite = 'https://www.zomato.com/'
const gesturePaperLink = 'https://scispace.com/pdf/uwb-gestures-a-public-dataset-of-dynamic-hand-gestures-oxchjzh84f.pdf'
const actionPaperLink = 'https://www.sciencedirect.com/science/article/abs/pii/S0957417420307703'
const csinetPaperLink = 'https://arxiv.org/pdf/1712.08919'
const csinetLstmPaperLink = 'https://arxiv.org/pdf/1807.11673'
const lensfreeProjectLink = 'https://drive.google.com/file/d/1in8Q_xY7uikWElkadZh22aPhAzlrKyVH/view?usp=sharing'

let orderedExperiences: Experience[] = []
let orderedEducations: Education[] = []

const orderElement = <T extends { time: string }>(a: T, b: T) => {
	const presentValues = ['present', 'now', 'current', 'today']
	if (presentValues.includes((a.time as string)?.split(' - ')[1]?.toLowerCase())) {
		return -1
	}
	const dateA = new Date((a.time as string)?.split(' - ')[1])
	const dateB = new Date((b.time as string)?.split(' - ')[1])
	return dateB.getTime() - dateA.getTime()
}

if (experiences.length > 0) {
	orderedExperiences = experiences.sort((a, b) => orderElement(a, b))
}

if (education.length > 0) {
	orderedEducations = education.sort((a, b) => orderElement(a, b))
}

// Welcome to Astro! Wondering what to do next? Check out the Astro documentation at https://docs.astro.build
// Don't want to use any of this? Delete everything in this file, the `assets`, `components`, and `layouts` directories, and start fresh.
---

<Layout>
	<!-- Hero Section -->
	<section class='flex items-center gap-12 border-b pb-12'>
		<Hero
			fullName={fullName}
			title={title}
			institute={institute}
			profilePicture={ProfilePictures}
		/>
	</section>

	<section class='pt-10'>
		<h2 class='text-2xl font-bold mb-4'>About Me</h2>
		<div class='space-y-4 text-base-content/90 leading-relaxed'>
			<p>
				I'm a Machine Learning Engineer at Adobe, currently working on foundation models for video generation and editing within the Firefly team. Previously, at Rephrase.ai, I contributed to the Zero-shot Talking Avatar model by building a large-scale, diverse talkinghead dataset. After Adobe acquired Rephrase.ai, this model was deployed on the Adobe Firefly platform as Translate Video.
			</p>
			<p>
				Before working on generative video systems, I was at Zomato, where I developed and deployed APIs for face recognition and liveliness detection, along with image enhancement and tagging models. I began my career at Samsung, working on gesture recognition, human action classification, and neural network based wireless signal compression.
			</p>
			<p>
				I graduated from IIT Kharagpur with a B.Tech in Electronics and Electrical Communication and a minor in Computer Science.
			</p>
		</div>
	</section>

	<section id='projects' class='pt-12'>
		<h2 class='text-2xl font-bold mb-6 border-b pb-2'>Projects</h2>
		<div class='grid grid-cols-1 gap-8 md:grid-cols-2 md:items-start'>
			<div class='flex justify-center'>
				<div class='h-[224px] rounded-lg'>
					<video
						class='h-full w-auto max-w-full rounded-lg object-contain'
						src={FireflyDemoVideo}
						autoplay
						loop
						controls
						muted
						playsinline
					>
						Your browser does not support the video tag.
					</video>
				</div>
			</div>

			<div class='space-y-4'>
				<h3 class='text-xl font-bold'>Adobe Translate Video</h3>
				<p class='text-base-content/90 leading-relaxed'>
					Built the data pipeline to process Adobe Stock and proprietary videos to train the Translate Video model.
				</p>
				<div class='flex flex-wrap items-center gap-4'>
					<a
						href={fireflyWebsite}
						target='_blank'
						rel='noopener noreferrer'
						class='group inline-flex items-center gap-2 text-xs text-zinc-500 transition-colors duration-300 hover:text-zinc-900'
					>
						<svg
							xmlns='http://www.w3.org/2000/svg'
							width='12'
							height='12'
							viewBox='0 0 24 24'
							fill='none'
							stroke='currentColor'
							stroke-width='2'
							stroke-linecap='round'
							stroke-linejoin='round'
							class='transition-transform duration-300 group-hover:translate-x-0.5 group-hover:-translate-y-0.5'
						>
							<path d='M7 7h10v10'></path>
							<path d='M7 17 17 7'></path>
						</svg>
						<span class='tracking-wider uppercase'>Website</span>
					</a>
					<div class='flex items-center gap-2'>
						<Image
							src={AdobeFireflyLogo}
							alt='Adobe Firefly logo'
							class='h-10 w-10 object-contain drop-shadow-sm'
						/>
						<Image
							src={RephraseLogo}
							alt='Rephrase.ai logo'
							class='h-16 w-16 object-contain drop-shadow-sm scale-125'
						/>
					</div>
				</div>
			</div>
		</div>

		<div class='mt-10 grid grid-cols-1 gap-8 md:grid-cols-2 md:items-start'>
			<div class='flex justify-center'>
				<div class='h-[224px] rounded-lg'>
					<Image
						src={TextToAvatarAsset}
						alt='Adobe Text to AI Avatar preview'
						class='h-full w-auto max-w-full rounded-lg object-contain'
					/>
				</div>
			</div>

			<div class='space-y-4'>
				<h3 class='text-xl font-bold'>Adobe Text to AI Avatar</h3>
				<p class='text-base-content/90 leading-relaxed'>
					Text to AI Avatar is built on top of the Translate Video model. The product uses predefined green-screen stock actors and text-to-speech to generate avatar based videos directly from text input.
				</p>
				<div class='flex flex-wrap items-center gap-4'>
					<a
						href={avatarWebsite}
						target='_blank'
						rel='noopener noreferrer'
						class='group inline-flex items-center gap-2 text-xs text-zinc-500 transition-colors duration-300 hover:text-zinc-900'
					>
						<svg
							xmlns='http://www.w3.org/2000/svg'
							width='12'
							height='12'
							viewBox='0 0 24 24'
							fill='none'
							stroke='currentColor'
							stroke-width='2'
							stroke-linecap='round'
							stroke-linejoin='round'
							class='transition-transform duration-300 group-hover:translate-x-0.5 group-hover:-translate-y-0.5'
						>
							<path d='M7 7h10v10'></path>
							<path d='M7 17 17 7'></path>
						</svg>
						<span class='tracking-wider uppercase'>Website</span>
					</a>
					<div class='flex items-center gap-2'>
						<Image
							src={AdobeFireflyLogo}
							alt='Adobe Firefly logo'
							class='h-10 w-10 object-contain drop-shadow-sm'
						/>
						<Image
							src={RephraseLogo}
							alt='Rephrase.ai logo'
							class='h-16 w-16 object-contain drop-shadow-sm scale-125'
						/>
					</div>
				</div>
			</div>
		</div>

		<div class='mt-10 grid grid-cols-1 gap-8 md:grid-cols-2 md:items-start'>
			<div class='flex justify-center'>
				<div class='h-[224px] rounded-lg'>
					<Image
						src={ImageEnhancementAsset}
						alt='Generative Image Enhancement preview'
						class='h-full w-auto max-w-full rounded-lg object-contain'
					/>
				</div>
			</div>

			<div class='space-y-4'>
				<h3 class='text-xl font-bold'>Generative Image Enhancement</h3>
				<p class='text-base-content/90 leading-relaxed'>
					Built and deployed an end-to-end API to enhance food catalog images by extracting dishes and inpainting backgrounds, and optimized the Stable Diffusion inference pipeline for production use through GPU and system-level improvements.
				</p>
				<div class='flex flex-wrap items-center gap-4'>
					<a
						href={zomatoWebsite}
						target='_blank'
						rel='noopener noreferrer'
						class='group inline-flex items-center gap-2 text-xs text-zinc-500 transition-colors duration-300 hover:text-zinc-900'
					>
						<svg
							xmlns='http://www.w3.org/2000/svg'
							width='12'
							height='12'
							viewBox='0 0 24 24'
							fill='none'
							stroke='currentColor'
							stroke-width='2'
							stroke-linecap='round'
							stroke-linejoin='round'
							class='transition-transform duration-300 group-hover:translate-x-0.5 group-hover:-translate-y-0.5'
						>
							<path d='M7 7h10v10'></path>
							<path d='M7 17 17 7'></path>
						</svg>
						<span class='tracking-wider uppercase'>Website</span>
					</a>
					<div class='flex items-center gap-2'>
						<Image
							src={ZomatoLogo}
							alt='Zomato logo'
							class='h-10 w-10 object-contain drop-shadow-sm'
						/>
					</div>
				</div>
			</div>
		</div>

		<div class='mt-10 grid grid-cols-1 gap-8 md:grid-cols-2 md:items-start'>
			<div class='flex justify-center'>
				<div class='h-[224px] rounded-lg'>
					<Image
						src={FacenetSiameseAsset}
						alt='Rider Face authentication preview'
						class='h-full w-auto max-w-full rounded-lg object-contain'
					/>
				</div>
			</div>

			<div class='space-y-4'>
				<h3 class='text-xl font-bold'>Rider Face Authentication</h3>
				<p class='text-base-content/90 leading-relaxed'>
					Built and deployed an end-to-end face recognition and liveliness detection API for rider onboarding and authentication. Fine-tuned a FaceNet-based siamese model on a large in-house dataset and replaced AWS Rekognition with an in-house system for better performance and cost control.
				</p>
				<div class='flex flex-wrap items-center gap-4'>
					<a
						href={zomatoWebsite}
						target='_blank'
						rel='noopener noreferrer'
						class='group inline-flex items-center gap-2 text-xs text-zinc-500 transition-colors duration-300 hover:text-zinc-900'
					>
						<svg
							xmlns='http://www.w3.org/2000/svg'
							width='12'
							height='12'
							viewBox='0 0 24 24'
							fill='none'
							stroke='currentColor'
							stroke-width='2'
							stroke-linecap='round'
							stroke-linejoin='round'
							class='transition-transform duration-300 group-hover:translate-x-0.5 group-hover:-translate-y-0.5'
						>
							<path d='M7 7h10v10'></path>
							<path d='M7 17 17 7'></path>
						</svg>
						<span class='tracking-wider uppercase'>Website</span>
					</a>
					<div class='flex items-center gap-2'>
						<Image
							src={ZomatoLogo}
							alt='Zomato logo'
							class='h-10 w-10 object-contain drop-shadow-sm'
						/>
					</div>
				</div>
			</div>
		</div>

		<div class='mt-10 grid grid-cols-1 gap-8 md:grid-cols-2 md:items-start'>
			<div class='flex justify-center'>
				<div class='h-[224px] rounded-lg'>
					<Image
						src={ClipImageTaggingAsset}
						alt='Indian Food Image Tagging preview'
						class='h-full w-auto max-w-full rounded-lg object-contain'
					/>
				</div>
			</div>

			<div class='space-y-4'>
				<h3 class='text-xl font-bold'>Dish Image Tagging</h3>
				<p class='text-base-content/90 leading-relaxed'>
					Built and deployed an image tagging API to generate relevant tags for catalog images and improve search relevance. Fine-tuned a CLIP-based model on an in-house dataset of 100k images covering top dishes and productionized it for low-latency batch predictions.
				</p>
				<div class='flex flex-wrap items-center gap-4'>
					<a
						href={zomatoWebsite}
						target='_blank'
						rel='noopener noreferrer'
						class='group inline-flex items-center gap-2 text-xs text-zinc-500 transition-colors duration-300 hover:text-zinc-900'
					>
						<svg
							xmlns='http://www.w3.org/2000/svg'
							width='12'
							height='12'
							viewBox='0 0 24 24'
							fill='none'
							stroke='currentColor'
							stroke-width='2'
							stroke-linecap='round'
							stroke-linejoin='round'
							class='transition-transform duration-300 group-hover:translate-x-0.5 group-hover:-translate-y-0.5'
						>
							<path d='M7 7h10v10'></path>
							<path d='M7 17 17 7'></path>
						</svg>
						<span class='tracking-wider uppercase'>Website</span>
					</a>
					<div class='flex items-center gap-2'>
						<Image
							src={ZomatoLogo}
							alt='Zomato logo'
							class='h-10 w-10 object-contain drop-shadow-sm'
						/>
					</div>
				</div>
			</div>
		</div>

		<div class='mt-10 grid grid-cols-1 gap-8 md:grid-cols-2 md:items-start'>
			<div class='flex justify-center'>
				<div class='h-[224px] rounded-lg'>
					<Image
						src={GestureRecognitionAsset}
						alt='Hand Gesture Recognition preview'
						class='h-full w-auto max-w-full rounded-lg object-contain'
					/>
				</div>
			</div>

			<div class='space-y-4'>
				<h3 class='text-xl font-bold'>Hand Gesture Recognition</h3>
				<p class='text-base-content/90 leading-relaxed'>
					Developed a deep learning based hand gesture recognition system using radar sensor data for touchless human-computer interaction. Trained and optimized CNN models on a inhouse radar gesture dataset. The system demonstrated strong generalization on real-world test data, highlighting the effectiveness of radar-based gesture recognition without reliance on cameras.
				</p>
				<div class='flex flex-wrap items-center gap-4'>
					<a
						href={gesturePaperLink}
						target='_blank'
						rel='noopener noreferrer'
						class='group inline-flex items-center gap-2 text-xs text-zinc-500 transition-colors duration-300 hover:text-zinc-900'
					>
						<svg
							xmlns='http://www.w3.org/2000/svg'
							width='12'
							height='12'
							viewBox='0 0 24 24'
							fill='none'
							stroke='currentColor'
							stroke-width='2'
							stroke-linecap='round'
							stroke-linejoin='round'
							class='transition-transform duration-300 group-hover:translate-x-0.5 group-hover:-translate-y-0.5'
						>
							<path d='M7 7h10v10'></path>
							<path d='M7 17 17 7'></path>
						</svg>
						<span class='tracking-wider uppercase'>Website</span>
					</a>
					<div class='flex items-center gap-2'>
						<Image
							src={SamsungLogo}
							alt='Samsung logo'
							class='h-10 w-10 object-contain drop-shadow-sm'
						/>
					</div>
				</div>
			</div>
		</div>

		<div class='mt-10 grid grid-cols-1 gap-8 md:grid-cols-2 md:items-start'>
			<div class='flex justify-center'>
				<div class='h-[224px] rounded-lg'>
					<Image
						src={HumanActionClassificationAsset}
						alt='Human action classification preview'
						class='h-full w-auto max-w-full rounded-lg object-contain'
					/>
				</div>
			</div>

			<div class='space-y-4'>
				<h3 class='text-xl font-bold'>Human action classification</h3>
				<p class='text-base-content/90 leading-relaxed'>
					Developed a deep learning-based human action classification system using Ultra-Wideband (UWB) radar data as a privacy-preserving alternative to camera-based monitoring in smart environments. Experimented with CNN and CNN-LSTM architectures, applied custom data augmentations such as Magnitude and Time Warp, and optimized models through hyperparameter tuning to achieve strong performance across multiple action classes on unseen data.
				</p>
				<div class='flex flex-wrap items-center gap-4'>
					<a
						href={actionPaperLink}
						target='_blank'
						rel='noopener noreferrer'
						class='group inline-flex items-center gap-2 text-xs text-zinc-500 transition-colors duration-300 hover:text-zinc-900'
					>
						<svg
							xmlns='http://www.w3.org/2000/svg'
							width='12'
							height='12'
							viewBox='0 0 24 24'
							fill='none'
							stroke='currentColor'
							stroke-width='2'
							stroke-linecap='round'
							stroke-linejoin='round'
							class='transition-transform duration-300 group-hover:translate-x-0.5 group-hover:-translate-y-0.5'
						>
							<path d='M7 7h10v10'></path>
							<path d='M7 17 17 7'></path>
						</svg>
						<span class='tracking-wider uppercase'>Website</span>
					</a>
					<div class='flex items-center gap-2'>
						<Image
							src={SamsungLogo}
							alt='Samsung logo'
							class='h-10 w-10 object-contain drop-shadow-sm'
						/>
					</div>
				</div>
			</div>
		</div>

		<div class='mt-10 grid grid-cols-1 gap-8 md:grid-cols-2 md:items-start'>
			<div class='flex justify-center'>
				<div class='h-[224px] rounded-lg'>
					<Image
						src={CsiNetAsset}
						alt='Deep Learning based CSI Compression preview'
						class='h-full w-auto max-w-full rounded-lg object-contain'
					/>
				</div>
			</div>

			<div class='space-y-4'>
				<h3 class='text-xl font-bold'>Deep Learning based CSI Compression</h3>
				<p class='text-base-content/90 leading-relaxed'>
					Developed a deep learning-based channel state information (CSI) compression and recovery system for massive MIMO networks. Implemented an autoencoder architecture with a CNN-based encoder and residual decoder to efficiently compress CSI for wireless feedback. Extended the baseline CsiNet model with a CsiNet-LSTM variant to better capture temporal correlations, improving NMSE from -17.3 dB to -23.3 dB over CsiNet.
				</p>
				<div class='flex flex-wrap items-center gap-4'>
					<a
						href={csinetPaperLink}
						target='_blank'
						rel='noopener noreferrer'
						class='group inline-flex items-center gap-2 text-xs text-zinc-500 transition-colors duration-300 hover:text-zinc-900'
					>
						<svg
							xmlns='http://www.w3.org/2000/svg'
							width='12'
							height='12'
							viewBox='0 0 24 24'
							fill='none'
							stroke='currentColor'
							stroke-width='2'
							stroke-linecap='round'
							stroke-linejoin='round'
							class='transition-transform duration-300 group-hover:translate-x-0.5 group-hover:-translate-y-0.5'
						>
							<path d='M7 7h10v10'></path>
							<path d='M7 17 17 7'></path>
						</svg>
						<span class='tracking-wider uppercase'>Paper 1</span>
					</a>
					<a
						href={csinetLstmPaperLink}
						target='_blank'
						rel='noopener noreferrer'
						class='group inline-flex items-center gap-2 text-xs text-zinc-500 transition-colors duration-300 hover:text-zinc-900'
					>
						<svg
							xmlns='http://www.w3.org/2000/svg'
							width='12'
							height='12'
							viewBox='0 0 24 24'
							fill='none'
							stroke='currentColor'
							stroke-width='2'
							stroke-linecap='round'
							stroke-linejoin='round'
							class='transition-transform duration-300 group-hover:translate-x-0.5 group-hover:-translate-y-0.5'
						>
							<path d='M7 7h10v10'></path>
							<path d='M7 17 17 7'></path>
						</svg>
						<span class='tracking-wider uppercase'>Paper 2</span>
					</a>
					<div class='flex items-center gap-2'>
						<Image
							src={SamsungLogo}
							alt='Samsung logo'
							class='h-10 w-10 object-contain drop-shadow-sm'
						/>
					</div>
				</div>
			</div>
		</div>

		<div class='mt-10 grid grid-cols-1 gap-8 md:grid-cols-2 md:items-start'>
			<div class='flex justify-center'>
				<div class='h-[224px] rounded-lg'>
					<Image
						src={LensfreeAsset}
						alt='Image Reconstruction Using Lensfree Microscopy preview'
						class='h-full w-auto max-w-full rounded-lg object-contain'
					/>
				</div>
			</div>

			<div class='space-y-4'>
				<h3 class='text-xl font-bold'>Image Reconstruction Using Lensfree Microscopy</h3>
				<p class='text-base-content/90 leading-relaxed'>
					Designed and developed a working prototype of a lensless microscope for computational imaging. Built a laser controller circuit to switch between multiple lasers and integrated it with a Raspberry Pi for system control. Applied digital holographic reconstruction techniques to convert captured diffraction patterns into high-resolution images, demonstrating a compact and cost-effective alternative to traditional lens-based microscopy.
				</p>
				<div class='flex flex-wrap items-center gap-4'>
					<a
						href={lensfreeProjectLink}
						target='_blank'
						rel='noopener noreferrer'
						class='group inline-flex items-center gap-2 text-xs text-zinc-500 transition-colors duration-300 hover:text-zinc-900'
					>
						<svg
							xmlns='http://www.w3.org/2000/svg'
							width='12'
							height='12'
							viewBox='0 0 24 24'
							fill='none'
							stroke='currentColor'
							stroke-width='2'
							stroke-linecap='round'
							stroke-linejoin='round'
							class='transition-transform duration-300 group-hover:translate-x-0.5 group-hover:-translate-y-0.5'
						>
							<path d='M7 7h10v10'></path>
							<path d='M7 17 17 7'></path>
						</svg>
						<span class='tracking-wider uppercase'>Website</span>
					</a>
					<div class='flex items-center gap-2'>
						<Image
							src={IitkgpLogo}
							alt='IIT Kharagpur logo'
							class='h-10 w-10 object-contain drop-shadow-sm'
						/>
					</div>
				</div>
			</div>
		</div>
	</section>

	<section class='pt-12'>
		{
			orderedEducations.length > 0 && (
				<section id='education' class='mb-12'>
					<h3 class='text-xl font-bold mb-6 border-b pb-2'>Education</h3>
					<CvTimeline elements={orderedEducations} colored={true} />
				</section>
			)
		}

		{
			orderedExperiences.length > 0 && (
				<section id='experience' class='mb-12'>
					<h3 class='text-xl font-bold mb-6 border-b pb-2'>Experience</h3>
					<CvTimeline elements={orderedExperiences} colored={true} />
				</section>
			)
		}
	</section>
</Layout>
